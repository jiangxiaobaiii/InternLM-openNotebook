# 8G 显存玩转书生大模型 Demo 

## 1 准备工作

使用studio.intern环境：

1、创建并启动开发机

![image-20240828094719415](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/b87d4c05f416d15dca5dc9ccbc5cbf52.png?raw=true)

2、ssh远程连接

![image](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/eaee675379c74a8743f153a8df0b0374.png?raw=true)

## 2 Cli Demo部署InternLM2-Chat-1.8B 模型

```bash
mkdir -p /root/demo
touch /root/demo/cli_demo.py
python /root/demo/cli_demo.py
```
cli_demo.py内容如下
```bash
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM


model_name_or_path = "/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b"

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='cuda:0')
model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')
model = model.eval()

system_prompt = """You are an AI assistant whose name is InternLM (书生·浦语).
- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.
- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.
"""

messages = [(system_prompt, '')]

print("=============Welcome to InternLM chatbot, type 'exit' to exit.=============")

while True:
    input_text = input("\nUser  >>> ")
    input_text = input_text.replace(' ', '')
    if input_text == "exit":
        break

    length = 0
    for response, _ in model.stream_chat(tokenizer, input_text, messages):
        if response is not None:
            print(response[length:], flush=True, end="")
            length = len(response)

```
模型部署效果如下图所示
![image22](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/0af9fca6c6312a750eee8cd6bbda04dc.png?raw=true)
Streamlit Web Demo 部署 InternLM2-Chat-1.8B 模型
![image11](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/dbf553b93b31b9a4ce6c1aed8d5993ba.png?raw=true)

## 3 进阶任务

### LMDeploy 部署 InternLM-XComposer2-VL-1.8B 模型

```bash
conda activate demo
pip install lmdeploy[all]==0.5.1
pip install timm==1.0.7

#接下来使用LMDeploy 启动一个与 InternLM-XComposer2-VL-1.8B 模型交互的 Gradio 服务
lmdeploy serve gradio /share/new_models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-1_8b --cache-max-entry-count 0.1
```


第一次运行并没有成功，原因与报错很多，也有显存问题，但是查看了显存占用情况发现并不是显存的问题

![image-20240828115213707](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/b9c5d0e829e47c8d5fa7da2c0d8b192b.png?raw=true)

接下来反复几次都没成功于是把开发机关了然后重启再次运行便成功了
打开了界面并且上传了一张图片
效果展示如下
![image5555](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/1835e244cc221d9a79f19b044c187dfe.png?raw=true)

### LMDeploy 部署 InternVL2-2B 模型

```bash
lmdeploy serve gradio /share/new_models/OpenGVLab/InternVL2-2B --cache-max-entry-count 0.1
```
在完成端口映射后，通过浏览器访问 http://localhost:6006 来启动我们的 Demo。在使用 Upload Image 上传图片后，输入信息最终得到输出结果
![image](https://github.com/jiangxiaobaiii/InternLM-openNotebook/blob/main/%E5%9F%BA%E7%A1%80%E5%B2%9B/%E7%AC%AC2%E5%85%B38G%E6%98%BE%E5%AD%98%E7%8E%A9%E8%BD%AC%E4%B9%A6%E4%B8%8A%E5%A4%A7%E6%A8%A1%E5%9E%8BDemo/6fb4670264f538e506278b477eeaab3d.png?raw=true)
